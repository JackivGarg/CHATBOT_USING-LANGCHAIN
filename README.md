# CHATBOT USING LANGCHAIN

A powerful AI Chatbot built using LangChain, LLMs, and Retrieval-Augmented Generation (RAG).  
This chatbot supports custom context ingestion, embeddings generation, and intelligent response generation using your own data.

 Features

RAG-based Question Answering
-  Embeddings generation and content generation using web scrapping and combining data from various sources 
-  Fast and optimized vector search (Chroma / FAISS supported)
-  Custom prompt templates for accurate responses
-  Modular code structure (easy to extend)
- Multiple Models created

## ðŸ“‚ Project Structure

Here is the overview of the project files and directories:

```text
project/
â”‚
â”œâ”€â”€ BENNY.py                     # Main chatbot script
â”œâ”€â”€ BENNY_PRO.py                 # Extended / advanced version
â”œâ”€â”€ common.py                    # Utility functions
â”œâ”€â”€ templates.py                 # Prompt templates
â”œâ”€â”€ store_model_embeddings.py    # Generates embeddings & vector DB
â”œâ”€â”€ requirements.txt             # Project dependencies
â”‚
â”œâ”€â”€ vector_created_2/            # Embeddings folder (ignored in git)
â”œâ”€â”€ context/                     # Private documents (ignored in git)
â”‚
â””â”€â”€ .env                         # API keys and secrets (ignored in git)
```
Some files such as **embeddings**, **context documents**, and the **.env file** are intentionally not included in this repository for privacy and future options.

These files contain:

- private project data  
- API keys / tokens  
- some really good content generated and then converted into embeddings

To run the pro model chatbot, users should add their own context files however base model embeddings are added in vector_created_2
